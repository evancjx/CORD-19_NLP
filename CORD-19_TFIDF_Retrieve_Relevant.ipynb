{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "haKIC2dMLprZ"
   },
   "source": [
    "### Initalize Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zC1xsv8uLpra"
   },
   "source": [
    "If you're running this script on Google Colab<br>\n",
    "Mount your Google drive: \n",
    "1. Click on the folder icon on the left\n",
    "2. Click Mount Drive\n",
    "3. The root directory would be /content/\n",
    "```\n",
    "# your Google Drive folder would be at:\n",
    "/content/drive/My Drive/\n",
    "```\n",
    "\n",
    "Change working directory:<br>\n",
    "1. Run this command:\n",
    "```\n",
    "%cd /content/drive/My Drive/<your folder>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 858,
     "status": "ok",
     "timestamp": 1591053891001,
     "user": {
      "displayName": "Evan Chang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLwuv1HrLfJCuFO3Jv9_dkRwGwd90aHRAVsWIh7Q=s64",
      "userId": "01810893482679501710"
     },
     "user_tz": -480
    },
    "id": "yizVYgqQS-nh",
    "outputId": "f1a7313b-bf80-4419-8381-8718a984dc11"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/My Drive/Data Science/Covid-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download optional (required) files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download nltk stopwords to use Stopwords\n",
    "```\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "```\n",
    "Download nltk wordnet to use WordNetLemmatizer:\n",
    "```\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "```\n",
    "Download nltk punkt to use Punkt Sentence Tokenizer\n",
    "```\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all\n",
    "Each paper are in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from src.covid_19_tp import authors_name, body_text, format_bib\n",
    "\n",
    "from os import walk as dir_list\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "folder = 'raw_data'\n",
    "data = [\n",
    "    {\n",
    "        'paper_id': file['paper_id'],\n",
    "        'title': file['metadata']['title'],\n",
    "        'authors': authors_name(file['metadata']['authors'], affiliation=True),\n",
    "\n",
    "        'abstract': body_text(file['abstract']),\n",
    "        'text': body_text(file['body_text']),\n",
    "\n",
    "        'bibliography': format_bib(file['bib_entries'])\n",
    "    }\n",
    "    for subdir, dirs, files in dir_list(f'./{folder}')\n",
    "    for file in tqdm(\n",
    "        [\n",
    "            json.load(open(f'{subdir}/{file}'))\n",
    "            for file in tqdm(files, desc=f'Loading all files in {subdir}')\n",
    "        ], desc=f'Reading individual files in {subdir}'\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create DataFrame with dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Corpus from Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "folder = 'processed_data'\n",
    "filename = 'raw_data_comm_use_subset_corpus'\n",
    "with open(f'./{folder}/{filename}.pkl', 'rb') as f:\n",
    "    corpus = pickle.load(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from src.tf_idf import corpus_tf_idf\n",
    "\n",
    "corpus_doc_tf_idf, term_doc_freq = corpus_tf_idf(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    corpus_doc_tf_idf: list of td-idf scores (terms: score) of each documents\n",
    "    score:\n",
    "        Low = frequent terms\n",
    "        High = rare terms\n",
    "'''\n",
    "corpus_doc_tf_idf[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    term_doc_freq: a dict (key: value pairs) of a term and it's count of occurrence in different documents\n",
    "'''\n",
    "term_doc_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load NLP functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.text_preprocessing import spacy_NLP, nltk_NLP\n",
    "spacy_tokenizer = spacy_NLP('en_core_web_sm').tokenize_API()\n",
    "nlp_tokenizer = nltk_NLP().tokenize_API()\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nlp_custom_tokenizer = nltk_NLP(stemming=PorterStemmer, lemmatisation=WordNetLemmatizer).custom_API()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.covid_19_tf_idf import search_relevant_articles_tf_idf\n",
    "from src.text_preprocessing import spacy_NLP, STOP_WORDS, text_preprocess\n",
    "\n",
    "tf_idf_search = lambda query: search_relevant_articles_tf_idf(\n",
    "    query = query, \n",
    "    n_articles = 10, \n",
    "    data_df = data, \n",
    "    corpus_doc_tf_idf = corpus_doc_tf_idf, \n",
    "    term_doc_freq = term_doc_freq,\n",
    "    query_preprocess_func = lambda text: text_preprocess(\n",
    "        text, tokenizer = spacy_tokenizer, stopwords = STOP_WORDS\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Relevant Articles based on question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = [\n",
    "    \"Is the virus transmitted by aerisol, droplets, food, close contact, fecal matter, or water\",\n",
    "    \"How long is the incubation period for the virus\",\n",
    "    \"Can the virus be transmitted asymptomatically or during the incubation period\",\n",
    "    \"What is the quantity of asymptomatic shedding\",\n",
    "    \"How does temperature and humidity affect the tramsmission of 2019-nCoV\",\n",
    "    \"How long can 2019-nCoV remain viable on inanimate, environmental, or common surfaces\",\n",
    "    \"What types of inanimate or environmental surfaces affect transmission, survival, or inactivation of 2019-nCov\",\n",
    "    \"Can the virus be found in nasal discharge, sputum, urine, fecal matter, or blood\",\n",
    "    \"What risk factors contribute to the severity of 2019-nCoV\",\n",
    "    \"How does hypertension affect patients\"\n",
    "]\n",
    "\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "for question in question_list:\n",
    "    print(question)\n",
    "    \n",
    "    result_df = tf_idf_search(question)\n",
    "    display(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
