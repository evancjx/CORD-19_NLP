{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "haKIC2dMLprZ"
   },
   "source": [
    "### Initalize Script\n",
    "If you're running this script on Google Colab<br>\n",
    "Mount your Google drive: \n",
    "1. Click on the folder icon on the left\n",
    "2. Click Mount Drive\n",
    "3. The root directory would be /content/\n",
    "```\n",
    "# your Google Drive folder would be at:\n",
    "/content/drive/My Drive/\n",
    "```\n",
    "\n",
    "Change working directory:<br>\n",
    "1. Run this command:\n",
    "```\n",
    "%cd /content/drive/My Drive/<your folder>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6zF_gdfx98x"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yizVYgqQS-nh"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/My Drive/Data Science/Covid-19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3GdhCff4x6o0"
   },
   "source": [
    "## Load NLP functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JLvb7VRZx6o0"
   },
   "outputs": [],
   "source": [
    "from src.text_preprocessing import spacy_NLP\n",
    "spacy_tokenizer = spacy_NLP('en_core_web_sm').tokenize_API()\n",
    "\n",
    "# from src.text_preprocessing import nltk_NLP\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# nlp_tokenizer = nltk_NLP().tokenize_API()\n",
    "# nlp_tokenizer = nltk_NLP(stemming=PorterStemmer, lemmatisation=WordNetLemmatizer).tokenize_API()\n",
    "\n",
    "from src.text_preprocessing import STOP_WORDS, text_preprocess\n",
    "text_prep = lambda text: text_preprocess(text, tokenizer=spacy_tokenizer, stopwords=STOP_WORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JoqEo-JRThB3"
   },
   "source": [
    "## Prepare and Pre-process Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7tNcPYnx6os"
   },
   "source": [
    "### Read all\n",
    "Each paper are in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u8rv5kB3x6ot"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from src.covid_19_tp import authors_name, body_text, format_bib\n",
    "\n",
    "from os import walk as dir_list\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "folder = 'raw_data/comm_use_subset'\n",
    "data = [\n",
    "    {\n",
    "        'paper_id': file['paper_id'],\n",
    "        'title': file['metadata']['title'],\n",
    "        'authors': authors_name(file['metadata']['authors'], affiliation=True),\n",
    "\n",
    "        'abstract': body_text(file['abstract']),\n",
    "        'text': body_text(file['body_text']),\n",
    "\n",
    "        'bibliography': format_bib(file['bib_entries'])\n",
    "    }\n",
    "    for subdir, dirs, files in dir_list(f'./{folder}')\n",
    "    for file in tqdm(\n",
    "        [\n",
    "            json.load(open(f'{subdir}/{file}'))\n",
    "            for file in tqdm(files, desc=f'Loading all files in {subdir}')\n",
    "        ], desc=f'Reading individual files in {subdir}'\n",
    "    )\n",
    "]\n",
    "\n",
    "import pandas as pd\n",
    "data = pd.DataFrame(data)\n",
    "\n",
    "# Save dataset to pickle for faster loading in the future\n",
    "from src.helper import pickle_dump\n",
    "filename = '_'.join(src_folder.split('/'))\n",
    "des_folder = 'processed_data'\n",
    "pickle_dump(f'{des_folder}/{filename}_df.pkl', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6gg2uqh2x6o2"
   },
   "source": [
    "### Create Corpus from dataset\n",
    "Save the corpus as pickle file to save time in the future; Load the pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2KiMHV5-x6o3"
   },
   "outputs": [],
   "source": [
    "from src.text_preprocessing import STOP_WORDS, text_preprocess\n",
    "from tqdm import tqdm\n",
    "corpus = [\n",
    "    text_preprocess(text, tokenizer=spacy_tokenizer, stopwords=STOP_WORDS)\n",
    "    for text in tqdm(list(data['title'] + ' ' + data['abstract'] + ' ' + data['text']))\n",
    "]\n",
    "\n",
    "from src.helper import pickle_dump\n",
    "filename = '_'.join(folder.split('/'))\n",
    "folder = 'processed_data'\n",
    "pickle_dump(f'./{folder}/{filename}_corpus.pkl', corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7Fw7XbJx6o8"
   },
   "source": [
    "### Conduct TF-IDF\n",
    "corpus_doc_tf_idf: list of td-idf scores (terms: score) of each documents<br>\n",
    "score:<br>\n",
    "> Low = frequent terms<br>\n",
    "> High = rare terms<br>\n",
    "\n",
    "```\n",
    "tfidf.corpus_doc_tfidf[:1]\n",
    "```\n",
    "\n",
    "term_doc_freq: a dict (key: value pairs) of a term and it's count of occurrence in different documents<br>\n",
    "\n",
    "```\n",
    "tfidf.term_doc_freq\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PaIZKSkyx6o9"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from src.tf_idf import TFIDF\n",
    "tfidf = TFIDF()\n",
    "tfidf.tfidf_corpus(corpus)\n",
    "\n",
    "from src.helper import pickle_dump\n",
    "folder = 'processed_data'\n",
    "filename = 'corpus_custom_tfidf'\n",
    "pickle_dump(f'./{folder}/{filename}.pkl', tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QhzSV1FKB2SS"
   },
   "source": [
    "### Get keywords for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-VdzdSaDB18A"
   },
   "outputs": [],
   "source": [
    "data = data.reindex(columns=list(data.columns)+['keywords'])\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "data['keywords'] = pd.Series(corpus).progress_apply(\n",
    "    lambda doc: tfidf.get_text_keywords(doc)\n",
    ")\n",
    "\n",
    "from src.helper import pickle_dump\n",
    "folder = 'processed_data'\n",
    "filename = 'raw_data_comm_use_subset_df_keyword'\n",
    "pickle_dump(f'./{folder}/{filename}.pkl', data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SdpuRLKnx6o5"
   },
   "source": [
    "## Load all pre-saved objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XltVaedcRjby"
   },
   "outputs": [],
   "source": [
    "from src.helper import pickle_load\n",
    "# filepath = 'processed_data/raw_data_comm_use_subset_df.pkl'\n",
    "# data = pickle_load(filepath)\n",
    "\n",
    "filepath = 'processed_data/raw_data_comm_use_subset_corpus.pkl'\n",
    "corpus = pickle_load(filepath)\n",
    "\n",
    "filepath = 'processed_data/corpus_custom_tfidf.pkl'\n",
    "tfidf = pickle_load(filepath)\n",
    "\n",
    "filepath = 'processed_data/raw_data_comm_use_subset_df_keyword.pkl'\n",
    "data = pickle_load(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "stswHuUPLRUs"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hZSjWOaMx6pF"
   },
   "source": [
    "### Search Relevant Articles based on question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOqvo_PHx6pG"
   },
   "outputs": [],
   "source": [
    "question_list = [\n",
    "    \"Is the virus transmitted by aerisol, droplets, food, close contact, fecal matter, or water\",\n",
    "    \"How long is the incubation period for the virus\",\n",
    "    \"Can the virus be transmitted asymptomatically or during the incubation period\",\n",
    "    \"What is the quantity of asymptomatic shedding\",\n",
    "    \"How does temperature and humidity affect the tramsmission of 2019-nCoV\",\n",
    "    \"How long can 2019-nCoV remain viable on inanimate, environmental, or common surfaces\",\n",
    "    \"What types of inanimate or environmental surfaces affect transmission, survival, or inactivation of 2019-nCov\",\n",
    "    \"Can the virus be found in nasal discharge, sputum, urine, fecal matter, or blood\",\n",
    "    \"What risk factors contribute to the severity of 2019-nCoV\",\n",
    "    \"How does hypertension affect patients\"\n",
    "]\n",
    "\n",
    "from src.covid_19_BM25 import BM25\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "    Prepare BM25 ranking\n",
    "    data_df: \n",
    "        a Pandas DataFrame with keywords column generated using TFIDF\n",
    "'''\n",
    "bm25 = BM25(data_df=data)\n",
    "\n",
    "for question in question_list:\n",
    "    print(question)\n",
    "    question = text_prep(question)\n",
    "\n",
    "    # Based on TFIDF and Dot Product of TFIDF scores\n",
    "    query_search = tfidf.search_similar(\n",
    "        query_tokens = question\n",
    "    )[:10]\n",
    "\n",
    "    result_df = pd.concat(\n",
    "        [\n",
    "            data.iloc[idx]\n",
    "            for idx, _ in query_search\n",
    "        ], ignore_index=True, axis=1\n",
    "    ).T[['title', 'abstract', 'text', 'keywords']]\n",
    "    display(result_df)\n",
    "\n",
    "    # Based on TFIDF, TFIDF generated keywords\n",
    "    result_bm25 = bm25.search_similar(\n",
    "        question.split(),\n",
    "        {'title': 1, 'abstract': 0.5, 'text': 2}\n",
    "    )\n",
    "    display(result_bm25)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vl9LT4ydx6pI"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CORD-19_TFIDF_Retrieve_Relevant.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
