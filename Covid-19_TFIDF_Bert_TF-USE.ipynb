{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 917,
     "status": "ok",
     "timestamp": 1591349809306,
     "user": {
      "displayName": "Evan Chang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLwuv1HrLfJCuFO3Jv9_dkRwGwd90aHRAVsWIh7Q=s64",
      "userId": "01810893482679501710"
     },
     "user_tz": -480
    },
    "id": "FmAimKsvlzJH",
    "outputId": "5f138250-a20b-4952-b90f-d52afbc30ec1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1130,
     "status": "ok",
     "timestamp": 1591349811297,
     "user": {
      "displayName": "Evan Chang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLwuv1HrLfJCuFO3Jv9_dkRwGwd90aHRAVsWIh7Q=s64",
      "userId": "01810893482679501710"
     },
     "user_tz": -480
    },
    "id": "GPrVAQr_mFn8",
    "outputId": "7d3edae9-84cf-48ec-c823-115b187ba16f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/My Drive/Data Science/Covid-19\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/My Drive/Data Science/Covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11616,
     "status": "ok",
     "timestamp": 1591349822319,
     "user": {
      "displayName": "Evan Chang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLwuv1HrLfJCuFO3Jv9_dkRwGwd90aHRAVsWIh7Q=s64",
      "userId": "01810893482679501710"
     },
     "user_tz": -480
    },
    "id": "PAFZpA29ltSe",
    "outputId": "7fb563ae-c0fd-4d3a-a4d9-2dc6bf3bbf81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 496 ms, sys: 549 ms, total: 1.05 s\n",
      "Wall time: 10.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filepath = 'processed_data/raw_data_comm_use_subset_df.pkl'\n",
    "\n",
    "import pickle\n",
    "with open(filepath, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 16343,
     "status": "ok",
     "timestamp": 1591349827851,
     "user": {
      "displayName": "Evan Chang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLwuv1HrLfJCuFO3Jv9_dkRwGwd90aHRAVsWIh7Q=s64",
      "userId": "01810893482679501710"
     },
     "user_tz": -480
    },
    "id": "7_Q5MyA_ltSj",
    "outputId": "b34bf799-0598-4dee-f04e-ab6c2f010f31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from src.text_preprocessing import nltk_NLP, spacy_NLP, STOP_WORDS, text_preprocess\n",
    "spacy_tokenizer = spacy_NLP('en_core_web_sm').tokenize_API()\n",
    "nlp_tokenizer = nltk_NLP().tokenize_API()\n",
    "\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "# from nltk.stem.wordnet import WordNetLemmatizer\n",
    "# nlp_custom_tokenizer = nltk_NLP(stemming=PorterStemmer, lemmatisation=WordNetLemmatizer).custom_API()\n",
    "\n",
    "text_prep = lambda text: text_preprocess(text, tokenizer=spacy_tokenizer, stopwords=STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vHNTGu2GltSl"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "folder = 'processed_data'\n",
    "filename = 'raw_data_comm_use_subset_corpus'\n",
    "with open(f'./{folder}/{filename}.pkl', 'rb') as f:\n",
    "    corpus = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73515,
     "status": "ok",
     "timestamp": 1591349887352,
     "user": {
      "displayName": "Evan Chang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLwuv1HrLfJCuFO3Jv9_dkRwGwd90aHRAVsWIh7Q=s64",
      "userId": "01810893482679501710"
     },
     "user_tz": -480
    },
    "id": "fs-DaDjMltSn",
    "outputId": "569468c4-0f1a-49fb-f7bf-f4192724f4fa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Conduct TFIDF for individual documents: 100%|██████████| 9315/9315 [00:37<00:00, 248.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54 s, sys: 850 ms, total: 54.8 s\n",
      "Wall time: 54.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from src.tf_idf import sklearn_TFIDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "sk_tfidf = sklearn_TFIDF()\n",
    "sk_tfidf.tfidf_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 139849,
     "status": "ok",
     "timestamp": 1591349955438,
     "user": {
      "displayName": "Evan Chang",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhLwuv1HrLfJCuFO3Jv9_dkRwGwd90aHRAVsWIh7Q=s64",
      "userId": "01810893482679501710"
     },
     "user_tz": -480
    },
    "id": "PVkKkhbDltSr",
    "outputId": "a67342c2-e4cc-483c-e1a0-2aacd464203a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForQuestionAnswering(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "QA_MODEL = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "QA_TOKENIZER = BertTokenizer.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')\n",
    "QA_MODEL.to(torch_device)\n",
    "# QA_MODEL.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hZzOlMMqltSu"
   },
   "outputs": [],
   "source": [
    "#tensorflow USE\n",
    "from os.path import isdir\n",
    "from os import mkdir\n",
    "import os\n",
    "\n",
    "# if not isdir('./tensorflow_USE'): mkdir('./tensorflow_USE') # If folder doesn't exist, create folder\n",
    "# os.environ[\"TFHUB_CACHE_DIR\"] = './tensorflow_USE' # Point to cache location\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "def embed_useT():\n",
    "    based_url = module='https://tfhub.dev/google/universal-sentence-encoder-large/'\n",
    "    if tf.__version__.split('.',1)[0] == '2':\n",
    "        return lambda x: hub.KerasLayer(based_url+'4')(x)['outputs']\n",
    "    else:\n",
    "        with tf.Graph().as_default():\n",
    "            sentences = tf.compat.v1.placeholder(dtype=tf.string)\n",
    "            embed = hub.Module(module_url+'3')\n",
    "            embed_input = embed(sentences)\n",
    "            session = tf.train.MonitoredSession()\n",
    "        return lambda x: session.run(embed_input, {sentences: x})\n",
    "\n",
    "embed_fn = embed_useT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C0h230VMltSp"
   },
   "outputs": [],
   "source": [
    "from src.covid_19_BERT import reconstructText\n",
    "from src.helper import chunks\n",
    "\n",
    "def Bert_SQuAD_predict(question, doc):\n",
    "    seq_ids = QA_TOKENIZER.encode(question, doc)\n",
    "\n",
    "    doc_tokens = doc.split()\n",
    "    \n",
    "    num_split = int(np.ceil(len(seq_ids)*1.1/256))\n",
    "    if num_split-1 > 0:\n",
    "        length_words = len(doc_tokens)\n",
    "        group_num = length_words//num_split\n",
    "        overlap = int(group_num*1.2//2)\n",
    "        \n",
    "        doc_partition = [\n",
    "            ' '.join(doc_tokens[start:end])\n",
    "            for start, end in chunks(length_words, group_num, overlap)\n",
    "        ]\n",
    "        doc_part_seq_ids = [QA_TOKENIZER.encode(question, dp) for dp in doc_partition]\n",
    "    else:\n",
    "        doc_part_seq_ids = [seq_ids]\n",
    "\n",
    "    answers, confidences = [], []\n",
    "\n",
    "    for part_seq_ids in doc_part_seq_ids:\n",
    "        part_seq_tokens = QA_TOKENIZER.convert_ids_to_tokens(part_seq_ids)\n",
    "\n",
    "        num_seg_a = part_seq_ids.index(QA_TOKENIZER.sep_token_id)+1\n",
    "        num_seg_b = len(part_seq_ids)-num_seg_a\n",
    "\n",
    "        segment_ids = [0]*num_seg_a+[1]*num_seg_b\n",
    "        assert len(segment_ids) == len(part_seq_ids)\n",
    "        n_ids = len(segment_ids)\n",
    "        \n",
    "        if n_ids > 512:\n",
    "            start_scores, end_scores = QA_MODEL(\n",
    "                torch.tensor([part_seq_ids[:512]]).to(torch_device), \n",
    "                token_type_ids=torch.tensor([segment_ids[:512]]).to(torch_device)\n",
    "            )\n",
    "        else:\n",
    "            start_scores, end_scores = QA_MODEL(\n",
    "                torch.tensor([part_seq_ids]).to(torch_device), \n",
    "                token_type_ids=torch.tensor([segment_ids]).to(torch_device)\n",
    "            )\n",
    "\n",
    "        start_scores, end_scores = start_scores[:,1:-1], end_scores[:,1:-1]\n",
    "\n",
    "        answer_start, answer_end = torch.argmax(start_scores), torch.argmax(end_scores)\n",
    "        answer = reconstructText(part_seq_tokens, answer_start, answer_end+2)\n",
    "        if not answer: continue\n",
    "\n",
    "        if answer.startswith('. ') or answer.startswith(', '): answer = answer[2:]\n",
    "\n",
    "        answers.append(answer)\n",
    "        confidences.append(start_scores[0,answer_start].item()+end_scores[0,answer_end].item())\n",
    "\n",
    "    if not answers: return {'answer': ''}\n",
    "    \n",
    "    best_idx = confidences.index(max(confidences))\n",
    "    confidence = confidences[best_idx]\n",
    "    answer = answers[best_idx]\n",
    "    \n",
    "    seq_tokens = QA_TOKENIZER.convert_ids_to_tokens(seq_ids)\n",
    "    return {\n",
    "        'answer': answer,\n",
    "        'confidence': -1000000 if answer.startswith('[CLS]') or answer.endswith('[SEP]') else confidence,\n",
    "        'abstract_bert': reconstructText(seq_tokens[seq_tokens.index('[SEP]')+1:])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fDSaaaEkltSw",
    "outputId": "d28bb918-ef52-474c-ad2c-812b4c8bda22"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><b>Query</b>: Is the virus transmitted by aerisol, droplets, food, close contact, fecal matter, or water</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:QA-Bert:Text Preprocess and TFIDF on question\n",
      "INFO:QA-Bert:Conducting BERT on TFIDF result...\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (14 > 512). Running this sequence through the model will result in indexing errors\n",
      "INFO:QA-Bert:Conducting sentence forming on Bert result\n",
      "INFO:QA-Bert:Conducting sementic matching using Tensorflow USE...\n",
      "INFO:QA-Bert:Forming final result...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a0acb3cda6288d12ce50136a88c013a3098ee3fd</td>\n",
       "      <td><div> <font color=\"red\">porcine epidemic diarrhea virus</font> (pedv) is the first viral pathogen confirmed to be widely transmissible in animal food.</div></td>\n",
       "      <td>0.411964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b15e513ac2f5696b1e51324fb0a3118c44a6a9e9</td>\n",
       "      <td><div> <font color=\"red\">repetitiveness and clustering of contacts are known to be relevant factors influencing the transmission of droplet or contact transmitted diseases</font> .</div></td>\n",
       "      <td>0.402222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56bea8bc53d2703d7d33244508932aa26d1ad442</td>\n",
       "      <td><div>a number of pepper-based foods tested positive <font color=\"red\">for pmmv, suggesting dietary origins for this virus. intriguingly, the fecal pmmv was infectious to host plants</font> , suggesting that humans might act as a vehicle for the dissemination of certain plant viruses.</div></td>\n",
       "      <td>0.390588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11ad2acc16067afbf2ce40d422647c3d899ecbd4</td>\n",
       "      <td><div>abstract background : the influenza a h1n1 virus can be transmitted via direct, indirect, and airborne route to non-infected subjects when an infected patient coughs, <font color=\"red\">which expels a number of different sized droplets to the surrounding environment as an aerosol</font> .</div></td>\n",
       "      <td>0.379066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Query</b>: How long is the incubation period for the virus</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:QA-Bert:Text Preprocess and TFIDF on question\n",
      "INFO:QA-Bert:Conducting BERT on TFIDF result...\n",
      "INFO:QA-Bert:Conducting sentence forming on Bert result\n",
      "INFO:QA-Bert:Conducting sementic matching using Tensorflow USE...\n",
      "INFO:QA-Bert:Forming final result...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37fe4be4d997e01fa069ab31bbe1a0090356500a</td>\n",
       "      <td><div> <font color=\"red\">abstract the incubation period of infectious diseases, the time from infection with a microorganism to onset of disease, is directly relevant to prevention and control. since explicit models of the incubation period enhance our understanding of the spread of disease, previous classic studies were revisited, focusing on the modeling methods employed and paying particular attention to relatively unknown historical efforts. the earliest study on the incubation period of pandemic influenza</font> was published in 1919, providing estimates of the incubation period of spanish flu using the daily incidence on ships departing from several ports in australia.</div></td>\n",
       "      <td>0.552168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210a892deb1c61577f6fba58505fd65356ce6636</td>\n",
       "      <td><div>based on the 95th percentile estimate of the incubation period, we recommend that the length of quarantine should be at <font color=\"red\">least 14 days</font> .</div></td>\n",
       "      <td>0.487088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4589d4013cf69c396e0fdb67131022fc11119654</td>\n",
       "      <td><div>we found a significant association between a longer incubation period and a greater risk of death among <font color=\"red\">human h7n9</font> cases.</div></td>\n",
       "      <td>0.441553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9f63dea0f76ee477d2e8e5209d40179db431ab1d</td>\n",
       "      <td><div>from the fitted distribution, the estimated incubation periods can <font color=\"red\">be longer than 10 days</font> for 8.</div></td>\n",
       "      <td>0.427425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4a077b9696d19b7d7fa3e71560b7fd5f414a4d19</td>\n",
       "      <td><div>using the travel history and symptom onset of 88 confirmed cases that were detected outside wuhan in the early outbreak phase, we estimate the mean incubation period to <font color=\"red\">be 6. 4 days</font> (95 % credible interval : 5.</div></td>\n",
       "      <td>0.390342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>599f44a88bfd9fcd7cc5b03f3b0bf01c9b3c5ba8</td>\n",
       "      <td><div>4 days) <font color=\"red\">for rotavirus</font> .</div></td>\n",
       "      <td>0.384971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cfffac30aa716974333312a44475097d94c8f475</td>\n",
       "      <td><div>we apply this method to data from a previously published literature review on the incubation period <font color=\"red\">of nine respiratory viral infections</font> .</div></td>\n",
       "      <td>0.317544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e26b6173b72a118e2b65869e3ba0cc176a3bb751</td>\n",
       "      <td><div>6) among cases <font color=\"red\">in saudi arabia</font> .</div></td>\n",
       "      <td>0.056545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Query</b>: Can the virus be transmitted asymptomatically or during the incubation period</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:QA-Bert:Text Preprocess and TFIDF on question\n",
      "INFO:QA-Bert:Conducting BERT on TFIDF result...\n",
      "INFO:QA-Bert:Conducting sentence forming on Bert result\n",
      "INFO:QA-Bert:Conducting sementic matching using Tensorflow USE...\n",
      "INFO:QA-Bert:Forming final result...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4589d4013cf69c396e0fdb67131022fc11119654</td>\n",
       "      <td><div>the incubation period is the delay from infection until onset of symptoms, <font color=\"red\">and varies from person to person</font> .</div></td>\n",
       "      <td>0.548831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210a892deb1c61577f6fba58505fd65356ce6636</td>\n",
       "      <td><div>using publicly available event-date data from the ongoing epidemic, the present study investigated the incubation period and other time intervals that govern the epidemiological dynamics <font color=\"red\">of covid-19 infections</font> .</div></td>\n",
       "      <td>0.480696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37fe4be4d997e01fa069ab31bbe1a0090356500a</td>\n",
       "      <td><div>the earliest study on the incubation period of pande <font color=\"red\">mic influenza</font> was published in 1919, providing estimates of the incubation period of spanish flu using the daily incidence on ships departing from several ports in australia.</div></td>\n",
       "      <td>0.439365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9f63dea0f76ee477d2e8e5209d40179db431ab1d</td>\n",
       "      <td><div>the incubation period of hfmd was typically described as <font color=\"red\">about 3-7 days</font> but empirical evidence is lacking.</div></td>\n",
       "      <td>0.424437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4a077b9696d19b7d7fa3e71560b7fd5f414a4d19</td>\n",
       "      <td><div>using the travel history and symptom onset of 88 confirmed cases that were detected outside wuhan in the early outbreak phase, we estimate the mean incubation period to <font color=\"red\">be 6. 4 days</font> (95 % credible interval : 5.</div></td>\n",
       "      <td>0.379779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cfffac30aa716974333312a44475097d94c8f475</td>\n",
       "      <td><div>we apply this method to data from a previously published literature review on the incubation period of <font color=\"red\">nine respiratory viral infections</font> .</div></td>\n",
       "      <td>0.375922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>599f44a88bfd9fcd7cc5b03f3b0bf01c9b3c5ba8</td>\n",
       "      <td><div>0 days (95 % ci <font color=\"red\">1. 4-2. 4 days</font> ) for rotavirus.</div></td>\n",
       "      <td>0.315835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>e26b6173b72a118e2b65869e3ba0cc176a3bb751</td>\n",
       "      <td><div>6) among cases <font color=\"red\">in saudi arabia</font> .</div></td>\n",
       "      <td>-0.022052</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Query</b>: What is the quantity of asymptomatic shedding</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:QA-Bert:Text Preprocess and TFIDF on question\n",
      "INFO:QA-Bert:Conducting BERT on TFIDF result...\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (8 > 512). Running this sequence through the model will result in indexing errors\n",
      "INFO:QA-Bert:Conducting sentence forming on Bert result\n",
      "INFO:QA-Bert:Conducting sementic matching using Tensorflow USE...\n",
      "INFO:QA-Bert:Forming final result...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aa2ed61346b7c005b96d661476a671b555b2a93a</td>\n",
       "      <td><div> <font color=\"red\">the asymptomatic infection was acquired via healthcare-associated transmission</font> .</div></td>\n",
       "      <td>0.242530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f849d3e71f4d2eae8a1e39802195bc9c06fc30ae</td>\n",
       "      <td><div>asymptomatic shedding among pediatric surgery patients (psps <font color=\"red\">) could potentially lead to progression of symptomatic diseases and cause outbreaks of respiratory diseases</font> .</div></td>\n",
       "      <td>0.235527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a204aafa38365dbcc0a26af3ca2c6d3313d7fab2</td>\n",
       "      <td><div>it is known that asymptomatic excretion of rsv occurs <font color=\"red\">in 15 %-20 % of the | 327 moreira et al. infected healthcare workers</font> (hcws).</div></td>\n",
       "      <td>0.229659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a20dad1dae885e38b8aeadb93c22d14a54c6388a</td>\n",
       "      <td><div>abstract background : foodborne norovirus outbreak data in japan from [ 2005 ] [ 2006 ], involving virological surveillance of all symptomatic and asymptomatic individuals, were reanalyzed to estimate the asymptomatic ratio of norovirus infection along with the risk of infection and <font color=\"red\">the probability of virus shedding</font> .</div></td>\n",
       "      <td>0.223836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05257a2230897ea006b3f68dbf0d71e1e7216f55</td>\n",
       "      <td><div> <font color=\"red\">long-term viral shedding for more than 30 days was significantly associated with prior allogeneic transplantation</font> (p = 0.</div></td>\n",
       "      <td>0.175452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4ea6973e872fb9116a21c6539d2aba2ea5c1337c</td>\n",
       "      <td><div>transfection of cells with sirna directed against pkc-δ <font color=\"red\">reduced ace2 shedding by 20 %</font> , while knockdown of pkc-ε was without effect.</div></td>\n",
       "      <td>0.134274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Query</b>: How does temperature and humidity affect the tramsmission of 2019-nCoV</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:QA-Bert:Text Preprocess and TFIDF on question\n",
      "INFO:QA-Bert:Conducting BERT on TFIDF result...\n",
      "INFO:QA-Bert:Conducting sentence forming on Bert result\n",
      "INFO:QA-Bert:Conducting sementic matching using Tensorflow USE...\n",
      "INFO:QA-Bert:Forming final result...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123ea6f7fb7c9dbde72ca2a6a5f1c5d0986966ab</td>\n",
       "      <td><div>m396, cr3014) that target the ace2 binding site of sars-cov failed to bind 2019-ncov spike protein, implying <font color=\"red\">that the difference in the rbd of sars-cov and 2019-ncov has a critical impact for the cross-reactivity of neutralizing antibodies</font> , and that it is still necessary to develop novel monoclonal antibodies that could bind specifically to 2019-ncov rbd.</div></td>\n",
       "      <td>-0.009120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4faf34d795e5ff74a886528e46268af783fe712b</td>\n",
       "      <td><div>structural analysis suggests that ace2 from these animals can potentially bind rbd of <font color=\"red\">2019-ncov, making them all possible natural hosts for the virus</font> .</div></td>\n",
       "      <td>-0.060918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>489040d34aa5dc8e6eba3d4e9d3d48f0bcc6061f</td>\n",
       "      <td><div>the proposal is a biologic that blocks 2019-ncov entry using a soluble version of the viral receptor, angiotensin-converting enzyme 2 (ace2), fused to an immunoglobulin fc domain (ace2-fc), providing a neutralizing antibody with maximal breath to avoid any viral escape, while also helping to recruit the immune system to <font color=\"red\">build lasting immunity</font> .</div></td>\n",
       "      <td>-0.113639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Query</b>: How long can 2019-nCoV remain viable on inanimate, environmental, or common surfaces</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:QA-Bert:Text Preprocess and TFIDF on question\n",
      "INFO:QA-Bert:Conducting BERT on TFIDF result...\n",
      "INFO:QA-Bert:Conducting sentence forming on Bert result\n",
      "INFO:QA-Bert:Conducting sementic matching using Tensorflow USE...\n",
      "INFO:QA-Bert:Forming final result...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4faf34d795e5ff74a886528e46268af783fe712b</td>\n",
       "      <td><div>2019-ncov is thought to <font color=\"red\">be transmitted through respiratory droplets</font> .</div></td>\n",
       "      <td>0.004231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123ea6f7fb7c9dbde72ca2a6a5f1c5d0986966ab</td>\n",
       "      <td><div>m396, cr3014) that target the ace2 binding site of sars-cov failed to <font color=\"red\">bind 2019-ncov spike protein</font> , implying that the difference in the rbd of sars-cov and 2019-ncov has a critical impact for the cross-reactivity of neutralizing antibodies, and that it is still necessary to develop novel monoclonal antibodies that could bind specifically to 2019-ncov rbd.</div></td>\n",
       "      <td>-0.086897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Query</b>: What types of inanimate or environmental surfaces affect transmission, survival, or  inactivation of 2019-nCov</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:QA-Bert:Text Preprocess and TFIDF on question\n",
      "INFO:QA-Bert:Conducting BERT on TFIDF result...\n",
      "INFO:QA-Bert:Conducting sentence forming on Bert result\n",
      "INFO:QA-Bert:Conducting sementic matching using Tensorflow USE...\n",
      "INFO:QA-Bert:Forming final result...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>sentence</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4faf34d795e5ff74a886528e46268af783fe712b</td>\n",
       "      <td><div>2019-ncov is thought to be transmitted <font color=\"red\">through respiratory droplets</font> .</div></td>\n",
       "      <td>0.175589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123ea6f7fb7c9dbde72ca2a6a5f1c5d0986966ab</td>\n",
       "      <td><div>m396, cr3014) that target the ace2 binding site of sars-co <font color=\"red\">v failed to bind 2019-ncov spike protein</font> , implying that the difference in the rbd of sars-cov and 2019-ncov has a critical impact for the cross-reactivity of neutralizing antibodies, and that it is still necessary to develop novel monoclonal antibodies that could bind specifically to 2019-ncov rbd.</div></td>\n",
       "      <td>0.153915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><b>Query</b>: Can the virus be found in nasal discharge, sputum, urine, fecal matter, or blood</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:QA-Bert:Text Preprocess and TFIDF on question\n",
      "INFO:QA-Bert:Conducting BERT on TFIDF result...\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (12 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (12 > 512). Running this sequence through the model will result in indexing errors\n",
      "WARNING:transformers.tokenization_utils:Token indices sequence length is longer than the specified maximum sequence length for this model (12 > 512). Running this sequence through the model will result in indexing errors\n",
      "INFO:QA-Bert:Conducting sentence forming on Bert result\n",
      "INFO:QA-Bert:Conducting sementic matching using Tensorflow USE...\n"
     ]
    }
   ],
   "source": [
    "question_list = [\n",
    "    \"Is the virus transmitted by aerisol, droplets, food, close contact, fecal matter, or water\",\n",
    "    \"How long is the incubation period for the virus\",\n",
    "    \"Can the virus be transmitted asymptomatically or during the incubation period\",\n",
    "    \"What is the quantity of asymptomatic shedding\",\n",
    "    \"How does temperature and humidity affect the tramsmission of 2019-nCoV\",\n",
    "    \"How long can 2019-nCoV remain viable on inanimate, environmental, or common surfaces\",\n",
    "    \"What types of inanimate or environmental surfaces affect transmission, survival, or  inactivation of 2019-nCov\",\n",
    "    \"Can the virus be found in nasal discharge, sputum, urine, fecal matter, or blood\",\n",
    "    \"What risk factors contribute to the severity of 2019-nCoV\",\n",
    "    \"How does hypertension affect patients\",\n",
    "    \"How does heart disease affect patients\",\n",
    "    \"How does copd affect patients\",\n",
    "    \"How does smoking affect 2019-nCoV patients\",\n",
    "    \"How does pregnancy affect patients\",\n",
    "    \"What are the case fatality rates for 2019-nCoV patients\",\n",
    "    \"What is the case fatality rate in Italy\",\n",
    "    \"What public health policies prevent or control the spread of 2019-nCoV\",\n",
    "    \"Can animals transmit 2019-nCoV\",\n",
    "    \"What animal did 2019-nCoV come from\",\n",
    "    \"What real-time genomic tracking tools exist\",\n",
    "    \"What regional genetic variations (mutations) exist\",\n",
    "    \"What effors are being done in asia to prevent further outbreaks\",\n",
    "    \"What drugs or therapies are being investigated\",\n",
    "    \"What clinical trials for hydroxychloroquine have been completed\",\n",
    "    \"What antiviral drug clinical trials have been completed\",\n",
    "    \"Are anti-inflammatory drugs recommended\",\n",
    "    \"Which non-pharmaceutical interventions limit tramsission\",\n",
    "    \"What are most important barriers to compliance\",\n",
    "    \"How does extracorporeal membrane oxygenation affect 2019-nCoV patients\",\n",
    "    \"What telemedicine and cybercare methods are most effective\",\n",
    "    \"How is artificial intelligence being used in real time health delivery\",\n",
    "    \"What adjunctive or supportive methods can help patients\",\n",
    "    \"What diagnostic tests (tools) exist or are being developed to detect 2019-nCoV\",\n",
    "    \"What is being done to increase testing capacity or throughput\",\n",
    "    \"What point of care tests are exist or are being developed\",\n",
    "    \"What is the minimum viral load for detection\",\n",
    "    \"What markers are used to detect or track COVID-19\",\n",
    "    \"What collaborations are happening within the research community\",\n",
    "    \"What are the major ethical issues related pandemic outbreaks\",\n",
    "    \"How do pandemics affect the physical and/or psychological health of doctors and nurses\",\n",
    "    \"What strategies can help doctors and nurses cope with stress in a pandemic\",\n",
    "    \"What factors contribute to rumors and misinformation\",\n",
    "    \"What is the immune system response to 2019-nCoV\",\n",
    "    \"Can personal protective equipment prevent the transmission of 2019-nCoV\",\n",
    "    \"Can 2019-nCoV infect patients a second time\",\n",
    "    \"What is the weighted prevalence of sars-cov-2 or covid-19 in general population\"\n",
    "]\n",
    "\n",
    "from src.covid_19_tf_idf import sk_tfidf_search\n",
    "from src.helper import sort_dict\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import logging; \n",
    "logging.basicConfig(); log = logging.getLogger('QA-Bert'); log.setLevel(logging.INFO)\n",
    "import pandas as pd\n",
    "for question in question_list:\n",
    "    display(HTML('<div><b>Query</b>: '+question+'</div>'))\n",
    "\n",
    "    log.info('Text Preprocess and TFIDF on question')\n",
    "    question = text_prep(question)\n",
    "    result_df = sk_tfidf_search(question, data, sk_tfidf)\n",
    "    \n",
    "    log.info('Conducting BERT on TFIDF result...')\n",
    "    bert_results = {}\n",
    "    for idx, doc in enumerate(result_df.abstract):\n",
    "        if not doc: continue        \n",
    "        result = Bert_SQuAD_predict(question, doc)\n",
    "        if result['answer']:\n",
    "            bert_results.update(\n",
    "                {\n",
    "                    result['confidence']: {\n",
    "                        'answer': result['answer'],\n",
    "                        'abstract_bert': result['abstract_bert'],\n",
    "                        'doc_idx': idx,\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "\n",
    "    confidence_list = list(bert_results.keys())\n",
    "    if confidence_list:\n",
    "        exp_scores = [\n",
    "            np.exp(score-max(confidence_list))\n",
    "            for score in confidence_list\n",
    "        ]\n",
    "        total = sum(exp_scores)\n",
    "        \n",
    "        bert_results = {\n",
    "            exp_scores[idx]/total : result\n",
    "            for idx, (confidence_score, result) in enumerate(bert_results.items())\n",
    "        }\n",
    "        \n",
    "    bert_results = sort_dict(bert_results, 'key', True)\n",
    "    \n",
    "    log.info('Conducting sentence forming on Bert result')\n",
    "    for score, result in bert_results.items():\n",
    "        if score <= 0 or score > 1 or len(result['answer'])==0 or not 'doc_idx' in result: continue\n",
    "\n",
    "        full_abs, bert_ans = result['abstract_bert'], result['answer']\n",
    "\n",
    "        split_abs = full_abs.split(bert_ans)\n",
    "        start_sentence = split_abs[0][split_abs[0].rfind('.')+1:]\n",
    "\n",
    "        if len(split_abs) == 1: sentence_end = ''\n",
    "        else:\n",
    "            sentance_end_pos = split_abs[1].find('. ')+1\n",
    "            if sentance_end_pos == 0: sentance_end = split_abs[1]\n",
    "            else: sentance_end = split_abs[1][:sentance_end_pos]\n",
    "        \n",
    "        result['sentence'] = {\n",
    "            'start': start_sentence,\n",
    "            'bert_ans': bert_ans,\n",
    "            'sentance_end': sentance_end\n",
    "        }\n",
    "        result['full_sentence'] = ''.join(result['sentence'].values())\n",
    "        \n",
    "    bert_results = {\n",
    "        score: result\n",
    "        for score, result in bert_results.items()\n",
    "        if result.get('full_sentence')\n",
    "    }\n",
    "    \n",
    "    log.info('Conducting sementic matching using Tensorflow USE...')\n",
    "    all_sent_embeddings = embed_fn(\n",
    "        [question]+[\n",
    "            result['full_sentence']\n",
    "            for result in bert_results.values()\n",
    "            if result.get('full_sentence')\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    similarity_matrix = np.inner(all_sent_embeddings, all_sent_embeddings)\n",
    "    rankings = similarity_matrix[1:,0]\n",
    "    \n",
    "    bert_results = {\n",
    "        rankings[idx]: bert_results[confidence_score]\n",
    "        for idx, confidence_score in enumerate(bert_results.keys())\n",
    "    }\n",
    "    \n",
    "    bert_results = sort_dict(bert_results, 'key', True)\n",
    "    \n",
    "    log.info('Forming final result...')\n",
    "    final_answer = [\n",
    "        {\n",
    "            'paper_id': result_df.iloc[result['doc_idx']]['paper_id'],\n",
    "            'sentence': '<div>'+''.join(\n",
    "                [part.strip() if idx!=1 else ' <font color=\"red\">'+part+'</font> ' for idx, part in enumerate(result['sentence'].values())]\n",
    "            )+'</div>',\n",
    "            'confidence': useT_score\n",
    "        }\n",
    "        for useT_score, result in bert_results.items()\n",
    "    ]\n",
    "    display(HTML(pd.DataFrame(final_answer).to_html(render_links=True, escape=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0kFM85qqltS0"
   },
   "outputs": [],
   "source": [
    "from src.covid_19_tf_idf import search_relevant_articles_tf_idf\n",
    "\n",
    "tf_idf_search = lambda query: search_relevant_articles_tf_idf(\n",
    "    query = query, \n",
    "    n_articles = 10, \n",
    "    data_df = data, \n",
    "    corpus_doc_tf_idf = corpus_doc_tf_idf, \n",
    "    term_doc_freq = term_doc_freq,\n",
    "    query_preprocess_func = lambda text: text_preprocess(text, tokenizer = spacy_tokenizer, stopwords = STOP_WORDS)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Covid-19 QA-Bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
